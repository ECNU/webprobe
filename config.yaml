url: ["https://www.ecnu.edu.cn", "https://www.baidu.com"]
scanner:
    crawl:
        depth: 2 # 爬虫时的链接深度，0 代表只检测url自身，以此类推
        timeout: 5 # 爬虫时访问每个url的超时时间
    check:
        ipv6: false # 默认仅使用ipv4检测，设置为true后进行ipv4和ipv6双检测
        retry:
            time: 1     # 重试次数
            interval: 1 # 重试间隔，秒为单位
        concurrency: 1000
        dialer_timeout: 10 # 请求每个URL时，建立连接的超时时间，秒为单位
        http_client_timeout: 15 # 请求每个URL的超时时间
        context_timeout: 1000 # 完成所有检测的超时时间，应足够大，否则会在检测某个url上一直挂起
push:
    push_to_prometheus: false
    push_gateway_url: "http://10.24.70.20:9091"
output: "output.html"
db:
    use_db: false
    db_path: "LinkPulse.db"
